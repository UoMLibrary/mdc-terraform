resource "aws_lambda_function" "create-transform-lambda-function" {
  count = length(var.transform-lambda-information)

  s3_bucket     = var.lambda-jar-bucket
  s3_key        = var.transform-lambda-information[count.index].jar_path
  runtime       = var.transform-lambda-information[count.index].runtime
  timeout       = 900
  role          = aws_iam_role.assume-lambda-role.arn
  layers        = concat(var.transform-lambda-information[count.index].transcription ? [] : [aws_lambda_layer_version.xslt-layer.arn], [aws_lambda_layer_version.transform-properties-layer[count.index].arn])
  function_name = substr("${var.environment}-${var.transform-lambda-information[count.index].name}", 0, 64)
  handler       = var.transform-lambda-information[count.index].handler
  publish       = true

  vpc_config {
    subnet_ids         = [data.aws_subnet.cudl_subnet.id]
    security_group_ids = [data.aws_security_group.default.id]
  }

  file_system_config {
    arn = aws_efs_access_point.efs-access-point.arn

    # Local mount path inside the lambda function. Must start with '/mnt/', and must not end with /
    local_mount_path = var.dst-efs-prefix
  }
}

resource "aws_lambda_alias" "create-transform-lambda-alias" {
  count = length(var.transform-lambda-information)

  name             = var.lambda-alias-name
  function_name    = aws_lambda_function.create-transform-lambda-function[count.index].arn
  function_version = var.transform-lambda-information[count.index].live_version
}

resource "aws_lambda_function" "create-db-lambda-function" {
  count = length(var.db-lambda-information)

  s3_bucket     = var.lambda-jar-bucket
  s3_key        = var.db-lambda-information[count.index].jar_path
  runtime       = var.db-lambda-information[count.index].runtime
  timeout       = 900
  role          = aws_iam_role.assume-lambda-role.arn
  layers        = [aws_lambda_layer_version.db-properties-layer[count.index].arn]
  function_name = substr("${var.environment}-${var.db-lambda-information[count.index].name}", 0, 64)
  handler       = var.db-lambda-information[count.index].handler
  publish       = true
}

resource "aws_lambda_alias" "create-db-lambda-alias" {
  count = length(var.db-lambda-information)

  name             = var.lambda-alias-name
  function_name    = aws_lambda_function.create-db-lambda-function[count.index].arn
  function_version = var.db-lambda-information[count.index].live_version
}

# TODO: finish parametising the contents of this file - not sure it all needs hard-coding...
resource "local_file" "create-local-transform-lambda-properties-file" {
  count = length(var.transform-lambda-information)

  content = <<-EOT
    # This file is generated by Terraform, and shouldn't need to be modified manually.

    # NOTE: transcriptions are written to cudl-transcriptions-staging bucket and only copied to
    # cudl-transcriptions (LIVE) bucket by bitbucket pipeline when data is published (so a commit is made
    # to cudl-data 'live' branch).

    VERSION=${upper(var.environment)}
    DST_BUCKET=${var.transform-lambda-information[count.index].transcription ? "${var.environment}-${var.transcriptions-bucket-name}" : "${var.environment}-${var.destination-bucket-name}"}
    DST_PREFIX=${var.dst-prefix}
    DST_EFS_PREFIX=${var.dst-efs-prefix}
    DST_S3_PREFIX=${var.dst-s3-prefix}
    TMP_DIR=${var.tmp-dir}
    LARGE_FILE_LIMIT=${var.large-file-limit}
    CHUNKS=${var.chunks}
    FUNCTION_NAME=${var.transform-lambda-information[count.index].transcription ? "${var.transcription-function-name}" : "${var.data-function-name}"}
    XSLT=/opt/xslt/msTeiPreFilter.xsl,/opt/xslt/jsonDocFormatter.xsl

    # Refresh URL settings
    # This is used when refreshing the cudl-viewer cache after new data is loaded.
    REFRESH_URL_ENABLE=true
    REFRESH_URL=https://cudl-dev.lib.cam.ac.uk/refresh
    REFRESH_URL_ENABLE_AUTH=true
    REFRESH_URL_USERNAME=qa
    REFRESH_URL_PASSWORD=qauser

    # Database details for editing/inserting collection data into CUDL
    DB_JDBC_DRIVER=
    DB_URL=
    DB_USERNAME=
    DB_PASSWORD=
  EOT

  filename = "${path.module}/properties_files/${var.environment}-${var.transform-lambda-information[count.index].name}/java/lib/${var.environment}-${var.transform-lambda-information[count.index].name}.properties"
}

data "archive_file" "zip_transform_properties_lambda_layer" {
  count = length(var.transform-lambda-information)

  type        = "zip"
  output_path = "${path.module}/zipped_properties_files/${var.environment}-${var.transform-lambda-information[count.index].name}.properties.zip"
  source_dir  = "${path.module}/properties_files/${var.environment}-${var.transform-lambda-information[count.index].name}"

  # Without the `depends_on` argument, the zip file creation fails because the file to zip
  # doesn't exist on the local filesystem yet
  depends_on = [local_file.create-local-transform-lambda-properties-file]
}

resource "aws_lambda_layer_version" "transform-properties-layer" {
  count = length(var.transform-lambda-information)

  filename   = "${path.module}/zipped_properties_files/${var.environment}-${var.transform-lambda-information[count.index].name}.properties.zip"
  layer_name = "${var.environment}-${var.transform-lambda-information[count.index].name}-properties"

  compatible_runtimes = [var.transform-lambda-information[count.index].runtime]
}

# TODO: finish parametising the contents of this file - not sure it all needs hard-coding...
resource "local_file" "create-local-db-lambda-properties-file" {
  count = length(var.db-lambda-information)

  content = <<-EOT
    # This file is generated by Terraform, and shouldn't need to be modified manually.

    # NOTE: transcriptions are written to cudl-transcriptions-staging bucket and only copied to
    # cudl-transcriptions (LIVE) bucket by bitbucket pipeline when data is published (so a commit is made
    # to cudl-data 'live' branch).

    VERSION=${upper(var.environment)}
    DST_BUCKET=
    DST_PREFIX=${var.dst-prefix}
    DST_EFS_PREFIX=${var.dst-efs-prefix}
    DST_S3_PREFIX=${var.dst-s3-prefix}
    TMP_DIR=${var.tmp-dir}
    LARGE_FILE_LIMIT=${var.large-file-limit}
    CHUNKS=${var.chunks}
    FUNCTION_NAME=${var.data-function-name}
    XSLT=/opt/xslt/msTeiPreFilter.xsl,/opt/xslt/jsonDocFormatter.xsl

    # Refresh URL settings
    # This is used when refreshing the cudl-viewer cache after new data is loaded.
    REFRESH_URL_ENABLE=true
    REFRESH_URL=https://cudl-dev.lib.cam.ac.uk/refresh
    REFRESH_URL_ENABLE_AUTH=true
    REFRESH_URL_USERNAME=qa
    REFRESH_URL_PASSWORD=qauser

    # Database details for editing/inserting collection data into CUDL
    DB_JDBC_DRIVER=
    DB_URL=
    DB_USERNAME=
    DB_PASSWORD=
  EOT

  filename = "${path.module}/properties_files/${var.environment}-${var.db-lambda-information[count.index].name}/java/lib/${var.environment}-${var.db-lambda-information[count.index].name}.properties"
}

data "archive_file" "zip_properties_lambda_layer" {
  count = length(var.db-lambda-information)

  type        = "zip"
  output_path = "${path.module}/zipped_properties_files/${var.environment}-${var.db-lambda-information[count.index].name}.properties.zip"
  source_dir  = "${path.module}/properties_files/${var.environment}-${var.db-lambda-information[count.index].name}"

  # Without the `depends_on` argument, the zip file creation fails because the file to zip
  # doesn't exist on the local filesystem yet
  depends_on = [local_file.create-local-db-lambda-properties-file]
}

resource "aws_lambda_layer_version" "db-properties-layer" {
  count = length(var.db-lambda-information)

  filename   = "${path.module}/zipped_properties_files/${var.environment}-${var.db-lambda-information[count.index].name}.properties.zip"
  layer_name = "${var.environment}-${var.db-lambda-information[count.index].name}-properties"

  compatible_runtimes = [var.db-lambda-information[count.index].runtime]
}

resource "aws_lambda_layer_version" "xslt-layer" {
  s3_bucket  = var.lambda-layer-bucket
  s3_key     = var.lambda-layer-filepath
  layer_name = "${var.environment}-${var.lambda-layer-name}"

  compatible_runtimes = distinct([for lambda in concat(var.transform-lambda-information, var.db-lambda-information) : lambda.runtime])
}

# Trigger lambda from the SQS queues
resource "aws_lambda_event_source_mapping" "sqs-trigger-lambda-transforms" {
  count = length(var.transform-lambda-information)

  event_source_arn = aws_sqs_queue.transform-lambda-sqs-queue[count.index].arn
  function_name    = aws_lambda_function.create-transform-lambda-function[count.index].arn
}
